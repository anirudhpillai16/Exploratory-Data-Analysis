nk2[nk1 > 1] <- (nk1[nk1 > 1])*(1 - 0.8/N) - 0.67
phik <- log((gamma(k1 + 1))*nk2/N)
rr <- run.rrline(k1,phik)
pkhat <- nk1/N
cilim<-1.96*sqrt((1-pkhat)/(nk1-(.47+.25*pkhat)*sqrt(nk1)))
rng <- range(c(phik-cilim,phik+cilim))
par(mfrow=c(1,2))
plot(k1,phik,ylim=rng,xlim=range(k0)+c(-0.5,0.5),xlab="k",ylab="phik",type="n",
main="Poisson plot", sub=
paste( paste("Intercept=",format(round(rr$coef[6,1],3))),
paste(", Slope=", format(round(rr$coef[6,2],3)))))
text(k1,phik,format(nk1))
segments(k1,phik-cilim,k1,phik+cilim,lty=2)
abline(rr$coef[6,1],rr$coef[6,2],col=2)
lamhat <- exp(rr$coef[6,2])
tmp <- ifelse(nk0 > 0, sqrt(2+4*nk0), 1)
exptd <- N*exp(-1*lamhat)*(lamhat^k0)/gamma(k0+1)
dk <- tmp - sqrt(4*exptd + 1)
plot(k0,dk,xlab="k",ylab="FT residual")
abline(h=c(-2,0,2),lty=c(2,1,2),col=c(2,1,2))
list(k=k1,nk=nk1,nkstar=nk2,phik=phik,cilim=cilim,
int=rr$coef[6,1],slope=rr$coef[6,2],res=dk,expected=exptd)
par(mfrow=c(1,1))
}
k <- 0:7
nk <- c(229,211,93,35,7,0,0,1)
poisplot(k,nk)
poisplot(k,nk,1:5)
k <- c(0:4,12)
nk <- c(38,26,8,2,1,1)
poisplot(k,nk)
poisplot(k,nk,1:5)
k <- 0:6
nk <- c(156, 63, 29, 8, 4, 1,1)
poisplot(k,nk)
poisplot(k,nk,1:6)
###########################################################
binomplot <- function(k,nk,which) {
lenk <- length(k)
if(missing(which))
which <- (1:lenk)
k0 <- k[which]
nk0 <- nk[which]
k1 <- k0[nk[which] > 0]
nk1 <- nk0[nk0 > 0]
N <- sum(nk1)
nk2 <- nk1
nk2[nk1==1] <- exp(-1)
nk2[nk1 > 1] <- (nk1[nk1 > 1])*(1 - 0.8/N) - 0.67
#  phik <- log((gamma(k1 + 1))*nk2/N)
phik <- log(nk2/N/choose(max(k1),k1))
rr <- run.rrline(k1,phik)
pkhat <- nk1/N
cilim<-1.96*sqrt((1-pkhat)/(nk1-(.47+.25*pkhat)*sqrt(nk1)))
rng <- range(c(phik-cilim,phik+cilim))
par(mfrow=c(1,2))
plot(k1,phik,ylim=rng,xlim=range(k0)+c(-0.5,0.5),xlab="k",ylab="phik",type="n",
main="Binomial plot", sub=
paste( paste("Intercept=",format(round(rr$coef[6,1],3))),
paste(", Slope=", format(round(rr$coef[6,2],3)))))
text(k1,phik,format(nk1))
segments(k1,phik-cilim,k1,phik+cilim,lty=2)
abline(rr$coef[6,1],rr$coef[6,2],col=2)
#  lamhat <- exp(rr$coef[6,2])
phat <- 1 - 1/(1+exp(rr$coef[6,2]))
tmp <- ifelse(nk0 > 0, sqrt(2+4*nk0), 1)
exptd <- N*exp(-1*lamhat)*(lamhat^k0)/gamma(k0+1)
dk <- tmp - sqrt(4*exptd + 1)
plot(k0,dk,xlab="k",ylab="FT residual")
abline(h=c(-2,0,2),lty=c(2,1,2),col=c(2,1,2))
list(k=k1,nk=nk1,nkstar=nk2,phik=phik,cilim=cilim,
int=rr$coef[6,1],slope=rr$coef[6,2],res=dk,expected=exptd)
par(mfrow=c(1,1))
}
k <- 0:12
nk <- c(1,3,4,23,25,19,18,5,1,1,0,0,0)
binomplot(k,nk)
binomplot(k,nk,1:10)
setwd('C:/EDA/Final Exam')
poisplot(as.integer(names(count_table_data)),x)
source('rrline.R')
poisplot(as.integer(names(count_table_data)),x)
obs1 = c(5, 3, 0, 2, 0, 3, 2, 3, 6, 1, 2, 1, 2, 1, 3, 3, 3, 5, 2, 4)
obs2 = c(4, 0, 2, 3, 7, 12, 3, 10, 9, 2, 3, 7, 7, 2, 3, 3, 6, 2, 4, 3)
obs3 = c(5, 2, 2, 4, 0, 4, 2, 5, 2, 3, 3, 6, 5, 8, 3, 6, 6, 0, 5, 2)
obs4 = c(2, 2, 6, 3, 4, 4, 2, 2, 4, 7, 5, 3, 3, 0, 2, 2, 2, 1, 3, 4)
obs5 = c(2, 2, 1, 1, 1, 2, 1, 4, 4, 3, 2, 1, 4, 1, 1, 1, 0, 0, 2, 0)
obs_total <- c(obs1,obs2,obs3,obs4,obs5)
years = c(1860:1959)
observation_year = cbind(obs_total,years)
combinedObservation = observation_year
Observations_dataSet = data.frame(combinedObservation)
colnames(Observations_dataSet) <- c("Inventions","Year")
uniqueOrderedDataFrame<-unique(Observations_dataSet)
count_table_data <- xtabs(~Inventions, data=uniqueOrderedDataFrame)
#Looking at the table it is a discrete frequency distributions. It may belong to poisson family or binomial family.For this we will try plotting poissonness plot, if we can fit a straight line then we can say that a poisson distribution is a good fit. If not we have to resort to plotting binomial distribution plot.
barplot(count_table_data)
count_table_data
x<-as.vector(count_table_data)
qqnorm(x)
qqline(x)
#Looking at qqnorm plot the distribution appears to be right skewed distribution.
hist(rbind(0:11,x),probability = TRUE, main = "Histogram of Density vs Inventions")
# skewness and kurtosis, they should be around (0,3)
skewness(count_table_data)
kurtosis(x)
```
```{r,eval=TRUE,warning=FALSE}
#b)
#install.packages("vcd")
library(vcd)
#Just a function that I found on internet, pretty good! Th slope and intercept differs a bit, but we can get a direct estimate of lambda as well.
distplot(count_table_data)
#Slope is 1.412, intercept is -3.94, lambda = 3.1, exp(slope) = 4.105
#We then call y-axis a count/disribution metameter (by analogy with the use, in bioassay, of "response metameter" and "dose metameter"). The slope of such a theoretical line
#identifies the main parameter of the theoretical distribution.
#Code which we learned in class, poisoness plot along with Freeman-Tukey residuals.
source("C:/EDA/Final Exam/poisplot.R")
source("C:/EDA/Final Exam/poisplot.R")
poisplot(as.integer(names(count_table_data)),x)
observation_1 = c(5, 3, 0, 2, 0, 3, 2, 3, 6, 1, 2, 1, 2, 1, 3, 3, 3, 5, 2, 4)
observation_2 = c(4, 0, 2, 3, 7, 12, 3, 10, 9, 2, 3, 7, 7, 2, 3, 3, 6, 2, 4, 3)
observation_3 = c(5, 2, 2, 4, 0, 4, 2, 5, 2, 3, 3, 6, 5, 8, 3, 6, 6, 0, 5, 2)
observation_4 = c(2, 2, 6, 3, 4, 4, 2, 2, 4, 7, 5, 3, 3, 0, 2, 2, 2, 1, 3, 4)
observation_5 = c(2, 2, 1, 1, 1, 2, 1, 4, 4, 3, 2, 1, 4, 1, 1, 1, 0, 0, 2, 0)
observations <- c(observation_1,observation_2,observation_3,observation_4,observation_5)
years = c(1860:1959)
observation_year = cbind(observations,years)
combinedObservation = observation_year
Observations_dataSet = data.frame(combinedObservation)
colnames(Observations_dataSet) <- c("Inventions","Year")
uniqueOrderedDataFrame<-unique(Observations_dataSet)
count_table_data <- xtabs(~Inventions, data=uniqueOrderedDataFrame)
#Looking at the table it is a discrete frequency distributions. It may belong to poisson family or binomial family.For this we will try plotting poissonness plot, if we
#can fit a straight line then we can say that a poisson distribution is a good fit. If not we have to resort to plotting binomial distribution plot.
barplot(count_table_data)
count_table_data
x<-as.vector(count_table_data)
qqnorm(x)
qqline(x)
#Looking at qqnorm plot the distribution appears to be right skewed distribution.
hist(rbind(0:11,x),probability = TRUE, main = "Histogram of Density vs #Inventions")
#Just making some observations on my own below.
#install.packages("e1071")
library(e1071)
# skewness and kurtosis, they should be around (0,3)
skewness(count_table_data)
kurtosis(x)
########
#b)
#install.packages("vcd")
library(vcd)
#Just a function that I found on internet, pretty good! Th slope and intercept differs a bit, but we can get a direct estimate of lambda as well.
distplot(count_table_data)
#Slope is 1.412, intercept is -3.94, lambda = 3.1, exp(slope) = 4.105
#We then call y-axis a count/disribution metameter (by analogy with the use, in bioassay, of "response metameter" and "dose metameter"). The slope of such a theoretical line
#identifies the main parameter of the theoretical distribution.
#Code which we learned in class, poisoness plot along with Freeman-Tukey residuals.
source("C:/EDA/Final Exam/poisplot.R")
poisplot(as.integer(names(count_table_data)),x)
If the frequencies are Poisson distributed, then the Freeman-Tukey residuals are approximately normal distributed.
When an isolated point strays from an apparently linear pattern of a
Poissonness plot, we may want to judge more formally whether it is unlikely
to have done so by chance.
Potting the residuals against k shows that the fit is quite good, except for the isolated count at k = 0 which does not follow the poisson distribution.
#c)
For an observed frequency ni and the estimated frequency mi, the Freeman-Tukey residual FTi is defined as FTi = sqrt(ni) + sqrt(ni + 1) - sqrt(4mi + 1).
Or Freeman-Tukey residuals = sqrt(4* observed value of k + 2) - sqrt(4* expected value of k +1)
Freeman and Tukey suggest this for a variance stabalizing transformation for Poisson data that leads to using the quantities defined above as residules.
For a Poisson random variable X with mean m, Freeman and Tukey (1949) point out  that the expected
value of sqrt(X) + sqrt(X+1) is well approximated by sqrt(4(n) + 1), and its variance
is close to 1. Substituting n for fitted value leads to the residual.
sqrt(x) + sqrt(x+1) - sqrt(4 * fitted value + 1)
whose behavior is approximately that of an observation from the standard Gaussian distribution.
All values except for k=0 are reasonable values, they follow poisson distribution because they are within the red-line in FT residual plot.
source('rrline.R')
poisplot <- function(k,nk,which) {
lenk <- length(k)
if(missing(which))
which <- (1:lenk)
k0 <- k[which]
nk0 <- nk[which]
k1 <- k0[nk[which] > 0]
nk1 <- nk0[nk0 > 0]
N <- sum(nk1)
nk2 <- nk1
nk2[nk1==1] <- exp(-1)
nk2[nk1 > 1] <- (nk1[nk1 > 1])*(1 - 0.8/N) - 0.67
phik <- log((gamma(k1 + 1))*nk2/N)
rr <- run.rrline(k1,phik)
pkhat <- nk1/N
cilim<-1.96*sqrt((1-pkhat)/(nk1-(.47+.25*pkhat)*sqrt(nk1)))
rng <- range(c(phik-cilim,phik+cilim))
par(mfrow=c(1,2))
plot(k1,phik,ylim=rng,xlim=range(k0)+c(-0.5,0.5),xlab="k",ylab="phik",type="n",
main="Poisson plot", sub=
paste( paste("Intercept=",format(round(rr$coef[6,1],3))),
paste(", Slope=", format(round(rr$coef[6,2],3)))))
text(k1,phik,format(nk1))
segments(k1,phik-cilim,k1,phik+cilim,lty=2)
abline(rr$coef[6,1],rr$coef[6,2],col=2)
lamhat <- exp(rr$coef[6,2])
tmp <- ifelse(nk0 > 0, sqrt(2+4*nk0), 1)
exptd <- N*exp(-1*lamhat)*(lamhat^k0)/gamma(k0+1)
dk <- tmp - sqrt(4*exptd + 1)
plot(k0,dk,xlab="k",ylab="FT residual")
abline(h=c(-2,0,2),lty=c(2,1,2),col=c(2,1,2))
list(k=k1,nk=nk1,nkstar=nk2,phik=phik,cilim=cilim,
int=rr$coef[6,1],slope=rr$coef[6,2],res=dk,expected=exptd)
par(mfrow=c(1,1))
}
k <- 0:7
nk <- c(229,211,93,35,7,0,0,1)
poisplot(k,nk)
poisplot(k,nk,1:5)
k <- c(0:4,12)
nk <- c(38,26,8,2,1,1)
poisplot(k,nk)
poisplot(k,nk,1:5)
k <- 0:6
nk <- c(156, 63, 29, 8, 4, 1,1)
poisplot(k,nk)
poisplot(k,nk,1:6)
###########################################################
binomplot <- function(k,nk,which) {
lenk <- length(k)
if(missing(which))
which <- (1:lenk)
k0 <- k[which]
nk0 <- nk[which]
k1 <- k0[nk[which] > 0]
nk1 <- nk0[nk0 > 0]
N <- sum(nk1)
nk2 <- nk1
nk2[nk1==1] <- exp(-1)
nk2[nk1 > 1] <- (nk1[nk1 > 1])*(1 - 0.8/N) - 0.67
#  phik <- log((gamma(k1 + 1))*nk2/N)
phik <- log(nk2/N/choose(max(k1),k1))
rr <- run.rrline(k1,phik)
pkhat <- nk1/N
cilim<-1.96*sqrt((1-pkhat)/(nk1-(.47+.25*pkhat)*sqrt(nk1)))
rng <- range(c(phik-cilim,phik+cilim))
par(mfrow=c(1,2))
plot(k1,phik,ylim=rng,xlim=range(k0)+c(-0.5,0.5),xlab="k",ylab="phik",type="n",
main="Binomial plot", sub=
paste( paste("Intercept=",format(round(rr$coef[6,1],3))),
paste(", Slope=", format(round(rr$coef[6,2],3)))))
text(k1,phik,format(nk1))
segments(k1,phik-cilim,k1,phik+cilim,lty=2)
abline(rr$coef[6,1],rr$coef[6,2],col=2)
#  lamhat <- exp(rr$coef[6,2])
phat <- 1 - 1/(1+exp(rr$coef[6,2]))
tmp <- ifelse(nk0 > 0, sqrt(2+4*nk0), 1)
exptd <- N*exp(-1*lamhat)*(lamhat^k0)/gamma(k0+1)
dk <- tmp - sqrt(4*exptd + 1)
plot(k0,dk,xlab="k",ylab="FT residual")
abline(h=c(-2,0,2),lty=c(2,1,2),col=c(2,1,2))
list(k=k1,nk=nk1,nkstar=nk2,phik=phik,cilim=cilim,
int=rr$coef[6,1],slope=rr$coef[6,2],res=dk,expected=exptd)
par(mfrow=c(1,1))
}
k <- 0:12
nk <- c(1,3,4,23,25,19,18,5,1,1,0,0,0)
binomplot(k,nk)
binomplot(k,nk,1:10)
source('rrline.R')
poisplot <- function(k,nk,which) {
lenk <- length(k)
if(missing(which))
which <- (1:lenk)
k0 <- k[which]
nk0 <- nk[which]
k1 <- k0[nk[which] > 0]
nk1 <- nk0[nk0 > 0]
N <- sum(nk1)
nk2 <- nk1
nk2[nk1==1] <- exp(-1)
nk2[nk1 > 1] <- (nk1[nk1 > 1])*(1 - 0.8/N) - 0.67
phik <- log((gamma(k1 + 1))*nk2/N)
rr <- run.rrline(k1,phik)
pkhat <- nk1/N
cilim<-1.96*sqrt((1-pkhat)/(nk1-(.47+.25*pkhat)*sqrt(nk1)))
rng <- range(c(phik-cilim,phik+cilim))
par(mfrow=c(1,2))
plot(k1,phik,ylim=rng,xlim=range(k0)+c(-0.5,0.5),xlab="k",ylab="phik",type="n",
main="Poisson plot", sub=
paste( paste("Intercept=",format(round(rr$coef[6,1],3))),
paste(", Slope=", format(round(rr$coef[6,2],3)))))
text(k1,phik,format(nk1))
segments(k1,phik-cilim,k1,phik+cilim,lty=2)
abline(rr$coef[6,1],rr$coef[6,2],col=2)
lamhat <- exp(rr$coef[6,2])
tmp <- ifelse(nk0 > 0, sqrt(2+4*nk0), 1)
exptd <- N*exp(-1*lamhat)*(lamhat^k0)/gamma(k0+1)
dk <- tmp - sqrt(4*exptd + 1)
plot(k0,dk,xlab="k",ylab="FT residual")
abline(h=c(-2,0,2),lty=c(2,1,2),col=c(2,1,2))
list(k=k1,nk=nk1,nkstar=nk2,phik=phik,cilim=cilim,
int=rr$coef[6,1],slope=rr$coef[6,2],res=dk,expected=exptd)
par(mfrow=c(1,1))
}
k <- 0:7
nk <- c(229,211,93,35,7,0,0,1)
poisplot(k,nk)
poisplot(k,nk,1:5)
k <- c(0:4,12)
nk <- c(38,26,8,2,1,1)
poisplot(k,nk)
poisplot(k,nk,1:5)
k <- 0:6
nk <- c(156, 63, 29, 8, 4, 1,1)
poisplot(k,nk)
poisplot(k,nk,1:6)
###########################################################
binomplot <- function(k,nk,which) {
lenk <- length(k)
if(missing(which))
which <- (1:lenk)
k0 <- k[which]
nk0 <- nk[which]
k1 <- k0[nk[which] > 0]
nk1 <- nk0[nk0 > 0]
N <- sum(nk1)
nk2 <- nk1
nk2[nk1==1] <- exp(-1)
nk2[nk1 > 1] <- (nk1[nk1 > 1])*(1 - 0.8/N) - 0.67
#  phik <- log((gamma(k1 + 1))*nk2/N)
phik <- log(nk2/N/choose(max(k1),k1))
rr <- run.rrline(k1,phik)
pkhat <- nk1/N
cilim<-1.96*sqrt((1-pkhat)/(nk1-(.47+.25*pkhat)*sqrt(nk1)))
rng <- range(c(phik-cilim,phik+cilim))
par(mfrow=c(1,2))
plot(k1,phik,ylim=rng,xlim=range(k0)+c(-0.5,0.5),xlab="k",ylab="phik",type="n",
main="Binomial plot", sub=
paste( paste("Intercept=",format(round(rr$coef[6,1],3))),
paste(", Slope=", format(round(rr$coef[6,2],3)))))
text(k1,phik,format(nk1))
segments(k1,phik-cilim,k1,phik+cilim,lty=2)
abline(rr$coef[6,1],rr$coef[6,2],col=2)
#  lamhat <- exp(rr$coef[6,2])
phat <- 1 - 1/(1+exp(rr$coef[6,2]))
tmp <- ifelse(nk0 > 0, sqrt(2+4*nk0), 1)
exptd <- N*exp(-1*lamhat)*(lamhat^k0)/gamma(k0+1)
dk <- tmp - sqrt(4*exptd + 1)
plot(k0,dk,xlab="k",ylab="FT residual")
abline(h=c(-2,0,2),lty=c(2,1,2),col=c(2,1,2))
list(k=k1,nk=nk1,nkstar=nk2,phik=phik,cilim=cilim,
int=rr$coef[6,1],slope=rr$coef[6,2],res=dk,expected=exptd)
par(mfrow=c(1,1))
}
k <- 0:12
nk <- c(1,3,4,23,25,19,18,5,1,1,0,0,0)
#binomplot(k,nk)
#binomplot(k,nk,1:10)
print('Jackknife estimate is')
leg.line<- c("1960","1980","2000")
---
title: "Take Home Final (S-520)"
author: "FNU Anirudh"
date: "December 12, 2015"
output: word_document
---
#Solution 1
```{r,eval=TRUE,warning=FALSE}
table60<- read.table('C:/Stats/TAKEHOME FINAL/election1960.txt',header=TRUE)
fit1<- lm(Party~Income,data = table60)
summary(fit1)
plot(table60$Income,table60$Party)
abline(fit1,col="red")
slope = cor(table60$Income,table60$Party) * sd(table60$Party) / sd(table60$Income)
intercept = mean(table60$Party) - slope * mean(table60$Income)
```
The equation of regression line is y=slope1* x + Intercept1
i.e. Party=0.104* Income + 3.266
#Solution 2
```{r, eval=TRUE,warning=FALSE}
table80<- read.table('C:/Stats/TAKEHOME FINAL/election1980.txt',header=TRUE)
fit2<- lm(Party~Income,data = table80)
summary(fit2)
slope2 = cor(table80$Income,table80$Party) * sd(table80$Party) / sd(table80$Income)
intercept2 = mean(table80$Party) - slope2 * mean(table80$Income)
plot(table80$Income,table80$Party)
abline(fit2,col="blue")
```
The equation of regression line is y=slope2* x + Intercept2
i.e. Party=0.352* Income + 2.528
#Solution 3
```{r,eval=TRUE,warning=FALSE}
table20<- read.table('C:/Stats/TAKEHOME FINAL/election2000.txt',header=TRUE)
fit3<- lm(Party~Income,data = table20)
summary(fit3)
slope3 = cor(table20$Income,table20$Party) * sd(table20$Party) / sd(table20$Income)
intercept3 = mean(table20$Party) - slope3 * mean(table20$Income)
plot(table20$Income,table20$Party)
abline(fit3,col="green")
```
The equation of regression line is y=slope3* x + Intercept3
i.e. Party=0.342* Income + 2.657
#Solution 4
```{r,eval=TRUE,warning=FALSE}
table_new<- rbind(table60,table80,table20)
plot(table_new$Income,table_new$Party)
abline(fit1,col="red")
abline(fit2,col="blue")
abline(fit3,col="green")
leg.line<- c("1960","1980","2000")
legend(list(x=3,y=7.3),legend=leg.line,col=c("red","blue","green"),lty=c(1,2,3),merge=TRUE)
```
#Solution 5
#Solution 6
```{r,eval=TRUE,warning=FALSE}
summary(fit1)
View(table_new)
View(table_new)
summary(fit1)$coeff
---
title: "Take Home Final (S-520)"
author: "FNU Anirudh"
date: "December 12, 2015"
output: word_document
---
#Solution 1
```{r,eval=TRUE,warning=FALSE}
table60<- read.table('C:/Stats/TAKEHOME FINAL/election1960.txt',header=TRUE)
fit1<- lm(Party~Income,data = table60)
summary(fit1)
plot(table60$Income,table60$Party)
abline(fit1,col="red")
slope = cor(table60$Income,table60$Party) * sd(table60$Party) / sd(table60$Income)
intercept = mean(table60$Party) - slope * mean(table60$Income)
```
The equation of regression line is y=slope1* x + Intercept1
i.e. Party=0.104* Income + 3.266
#Solution 2
```{r, eval=TRUE,warning=FALSE}
table80<- read.table('C:/Stats/TAKEHOME FINAL/election1980.txt',header=TRUE)
fit2<- lm(Party~Income,data = table80)
summary(fit2)
slope2 = cor(table80$Income,table80$Party) * sd(table80$Party) / sd(table80$Income)
intercept2 = mean(table80$Party) - slope2 * mean(table80$Income)
plot(table80$Income,table80$Party)
abline(fit2,col="blue")
```
The equation of regression line is y=slope2* x + Intercept2
i.e. Party=0.352* Income + 2.528
#Solution 3
```{r,eval=TRUE,warning=FALSE}
table20<- read.table('C:/Stats/TAKEHOME FINAL/election2000.txt',header=TRUE)
fit3<- lm(Party~Income,data = table20)
summary(fit3)
slope3 = cor(table20$Income,table20$Party) * sd(table20$Party) / sd(table20$Income)
intercept3 = mean(table20$Party) - slope3 * mean(table20$Income)
plot(table20$Income,table20$Party)
abline(fit3,col="green")
```
The equation of regression line is y=slope3* x + Intercept3
i.e. Party=0.342* Income + 2.657
#Solution 4
```{r,eval=TRUE,warning=FALSE}
table60$Year<-rep("1960",nrow(table60))
table80$Year<-rep("1980",nrow(table80))
table20$Year<-rep("2000",nrow(table20))
table_new<-rbind(table60,table80,table20)
plot(table_new$Income,table_new$Party)
abline(fit1,col="red")
abline(fit2,col="blue")
abline(fit3,col="green")
leg.line<- c("1960","1980","2000")
legend(list(x=3,y=7.3),legend=leg.line,col=c("red","blue","green"),lty=c(1,2,3),merge=TRUE)
```
#Solution 5
* In 1960, Most of the High Income people were in between Independent Democrat and true independent, even low class preferred the same.
* In 2000, Low Income people are either True independent or weak democrat whereas High Income people are Independent democrat or true Independent.
To summarize, People in 2000 are more inclined towards republicans compared to 1960's or earlier.
#Solution 6
```{r,eval=TRUE,warning=FALSE}
summary(fit1)$coeff
par(mfrow=c(1,2))
plot(fit1$residuals,main="Residual Plot of Party and Income 1960")
qqnorm(fit1$residuals,main="Residual QQplot of Party and Income 1960")
```
Slope=0.104 has confidence interval (-0.02,0.23)
We should not take it's meaning literally because
* As seen from Residual Plots there is no linearity between Party and Income. Linear Regression depends on assumptions like Linearity, Homoscedascity, Independence and Normality of errors.
* Linear Regression is not a good fit for categorical data,Both Party and Income are categorical data which should be fit using different model.
#Solution 7
```{r,eval=TRUE,warning=FALSE}
fit<- lm(table_new$Age~table_new$Year)
```
fit<- lm(table_new$Age~table_new$Year)
anova(fit)
female1960<- nrow(table60[table60$Sex==2])
female1960<- nrow(table60[table60$Sex==2,])
femaleratio<- female1960/nrow(table60)
maleratio<- 1-femaleratio
female60<- nrow(table60[table60$Sex==2,])
femaleratio60<- female60/nrow(table60)
maleratio60<- 1-femaleratio
female2000<-nrow(table20[table20$Sex==2,])
female20<-nrow(table20[table20$Sex==2,])
male20<-nrow(table20[table20$Sex==1,])
observed<- c(female20,male20)
expfem20<- femaleratio60 *nrow(table20)
expmal20<- maleratio60 *nrow(table20)
expected<-c(expfem20,expmal20)
X2 = sum((observed - Expected)^2 / Expected)
X2 = sum((observed - expected)^2 / expected)
p_value=1 - pchisq(X2, df=2-0-1)
p_value
G2 = 2 * sum(observed * log(observed/expected))
1 - pchisq(G2, df=2-0-1)
